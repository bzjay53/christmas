#!/usr/bin/env python3
"""
Production Deployment Script

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”, ì •ì‹ ë²„ì „ ë°°í¬(WBS 7.5.2)ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë„êµ¬ë¡œì„œ, ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
- ì •ì‹ ë²„ì „ íƒœê·¸ ìƒì„± ë° ë°°í¬ ë¸Œëœì¹˜ ì¤€ë¹„
- í”„ë¡œë•ì…˜ í™˜ê²½ì— ë¸”ë£¨/ê·¸ë¦° ë°°í¬ ì‹¤í–‰
- ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜í–‰
- íŠ¸ë˜í”½ ì „í™˜ (ì¹´ë‚˜ë¦¬ ë°°í¬ ë°©ì‹)
- ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ ë° ê²€ì¦
"""

import os
import sys
import json
import time
import logging
import argparse
import subprocess
from datetime import datetime, timedelta
import requests

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("production_deployment.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("ProductionDeployment")

class ProductionDeployer:
    def __init__(self, config_path, dry_run=False):
        self.dry_run = dry_run
        self.config_path = config_path
        self.load_config()
        self.deployment_success = False
        self.version = "1.0.0"
        self.deployment_id = f"deploy-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        
    def load_config(self):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.config_path, 'r') as f:
                self.config = json.load(f)
            logger.info(f"ì„¤ì • íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {self.config_path}")
        except Exception as e:
            logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            sys.exit(1)
    
    def prepare_deployment(self):
        """ë°°í¬ ì¤€ë¹„"""
        logger.info("ë°°í¬ ì¤€ë¹„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            # ë°°í¬ ë¸Œëœì¹˜ ìƒì„±
            current_branch = subprocess.check_output(["git", "rev-parse", "--abbrev-ref", "HEAD"]).decode().strip()
            logger.info(f"í˜„ì¬ ë¸Œëœì¹˜: {current_branch}")
            
            # master ë¸Œëœì¹˜ë¡œ ì „í™˜
            if current_branch != "main" and not self.dry_run:
                subprocess.run(["git", "checkout", "main"], check=True)
                logger.info("main ë¸Œëœì¹˜ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")
            
            # main ë¸Œëœì¹˜ ìµœì‹ í™”
            if not self.dry_run:
                subprocess.run(["git", "pull", "origin", "main"], check=True)
                logger.info("main ë¸Œëœì¹˜ë¥¼ ìµœì‹ í™”í–ˆìŠµë‹ˆë‹¤.")
            
            # ë°°í¬ìš© íƒœê·¸ ìƒì„±
            tag_name = f"v{self.version}"
            if not self.dry_run:
                # íƒœê·¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                result = subprocess.run(["git", "tag", "-l", tag_name], capture_output=True)
                if tag_name in result.stdout.decode():
                    logger.warning(f"íƒœê·¸ {tag_name}ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë°°í¬ë¥¼ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                else:
                    subprocess.run(["git", "tag", "-a", tag_name, "-m", f"ì •ì‹ ë²„ì „ {self.version} ë°°í¬"], check=True)
                    subprocess.run(["git", "push", "origin", tag_name], check=True)
                    logger.info(f"ë°°í¬ íƒœê·¸ {tag_name}ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            # ë°°í¬ ë¸Œëœì¹˜ ìƒì„±
            release_branch = f"release/v{self.version}"
            if not self.dry_run:
                # ë¸Œëœì¹˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                result = subprocess.run(["git", "branch", "--list", release_branch], capture_output=True)
                if release_branch in result.stdout.decode():
                    logger.warning(f"ë¸Œëœì¹˜ {release_branch}ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ê¸°ì¡´ ë¸Œëœì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    subprocess.run(["git", "checkout", release_branch], check=True)
                else:
                    subprocess.run(["git", "checkout", "-b", release_branch], check=True)
                    subprocess.run(["git", "push", "-u", "origin", release_branch], check=True)
                    logger.info(f"ë°°í¬ ë¸Œëœì¹˜ {release_branch}ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            # ë²„ì „ ì •ë³´ ì—…ë°ì´íŠ¸
            if not self.dry_run:
                # VERSION íŒŒì¼ ì—…ë°ì´íŠ¸
                with open("VERSION", "w") as f:
                    f.write(self.version)
                
                # ë³€ê²½ì‚¬í•­ ì»¤ë°‹
                subprocess.run(["git", "add", "VERSION"], check=True)
                subprocess.run(["git", "commit", "-m", f"ë²„ì „ {self.version} ì •ë³´ ì—…ë°ì´íŠ¸"], check=True)
                subprocess.run(["git", "push", "origin", release_branch], check=True)
                logger.info("ë²„ì „ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
            
            logger.info("ë°°í¬ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"ë°°í¬ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def execute_deployment(self):
        """ë°°í¬ ì‹¤í–‰"""
        logger.info("ë°°í¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        
        try:
            # Docker ì´ë¯¸ì§€ ë¹Œë“œ
            if not self.dry_run:
                image_name = f"{self.config['docker']['registry']}/christmas:v{self.version}"
                subprocess.run(["docker", "build", "-t", image_name, "."], check=True)
                logger.info(f"Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí–ˆìŠµë‹ˆë‹¤: {image_name}")
                
                # Docker ì´ë¯¸ì§€ í‘¸ì‹œ
                subprocess.run(["docker", "push", image_name], check=True)
                logger.info(f"Docker ì´ë¯¸ì§€ë¥¼ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— í‘¸ì‹œí–ˆìŠµë‹ˆë‹¤: {image_name}")
            
            # ê·¸ë¦° í™˜ê²½ ë°°í¬
            if not self.dry_run:
                green_env = self.config['environments']['green']
                
                # ê¸°ì¡´ ê·¸ë¦° í™˜ê²½ ë°±ì—…
                green_backup_cmd = [
                    "ssh", 
                    f"{self.config['ssh']['user']}@{green_env['host']}", 
                    f"cd {green_env['deploy_path']} && docker-compose down && tar -czf config_backup_$(date +%Y%m%d_%H%M%S).tar.gz config/"
                ]
                subprocess.run(green_backup_cmd, check=True)
                logger.info("ê·¸ë¦° í™˜ê²½ ì„¤ì •ì„ ë°±ì—…í–ˆìŠµë‹ˆë‹¤.")
                
                # ê·¸ë¦° í™˜ê²½ ë°°í¬
                green_deploy_cmd = [
                    "ssh", 
                    f"{self.config['ssh']['user']}@{green_env['host']}", 
                    f"cd {green_env['deploy_path']} && " +
                    f"echo 'VERSION={self.version}' > .env && " +
                    f"echo 'IMAGE={image_name}' >> .env && " +
                    f"docker-compose pull && " +
                    f"docker-compose up -d"
                ]
                subprocess.run(green_deploy_cmd, check=True)
                logger.info("ê·¸ë¦° í™˜ê²½ì— ìƒˆ ë²„ì „ì„ ë°°í¬í–ˆìŠµë‹ˆë‹¤.")
            
            # ê·¸ë¦° í™˜ê²½ ìƒíƒœ í™•ì¸
            if not self.dry_run:
                health_check_url = f"https://{green_env['domain']}/health"
                retry_count = 0
                max_retries = 10
                
                while retry_count < max_retries:
                    try:
                        response = requests.get(health_check_url, timeout=10)
                        if response.status_code == 200 and response.json().get("status") == "ok":
                            logger.info("ê·¸ë¦° í™˜ê²½ ìƒíƒœ í™•ì¸ ì„±ê³µ!")
                            break
                        else:
                            logger.warning(f"ê·¸ë¦° í™˜ê²½ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                    except Exception as e:
                        logger.warning(f"ê·¸ë¦° í™˜ê²½ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    
                    retry_count += 1
                    logger.info(f"ì¬ì‹œë„ ì¤‘... ({retry_count}/{max_retries})")
                    time.sleep(30)  # 30ì´ˆ ëŒ€ê¸°
                
                if retry_count >= max_retries:
                    logger.error("ê·¸ë¦° í™˜ê²½ ìƒíƒœ í™•ì¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë°°í¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    return False
            
            logger.info("ë°°í¬ ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"ë°°í¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def migrate_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            if not self.dry_run:
                green_env = self.config['environments']['green']
                
                # ë§ˆì´ê·¸ë ˆì´ì…˜ ëª…ë ¹ ì‹¤í–‰
                migration_cmd = [
                    "ssh", 
                    f"{self.config['ssh']['user']}@{green_env['host']}", 
                    f"cd {green_env['deploy_path']} && " +
                    f"docker-compose exec -T app python manage.py db upgrade"
                ]
                subprocess.run(migration_cmd, check=True)
                logger.info("ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
            
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def switch_traffic(self):
        """íŠ¸ë˜í”½ ì „í™˜"""
        logger.info("íŠ¸ë˜í”½ ì „í™˜(ì¹´ë‚˜ë¦¬ ë°°í¬)ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            if not self.dry_run:
                # ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • ì—…ë°ì´íŠ¸
                load_balancer_host = self.config['load_balancer']['host']
                load_balancer_config_path = self.config['load_balancer']['config_path']
                
                # ì´ˆê¸° íŠ¸ë˜í”½ ë°°ë¶„ (10% ê·¸ë¦° í™˜ê²½ìœ¼ë¡œ ì „í™˜)
                initial_split_cmd = [
                    "ssh", 
                    f"{self.config['ssh']['user']}@{load_balancer_host}", 
                    f"cd {load_balancer_config_path} && " +
                    f"sed -i 's/blue_weight=100/blue_weight=90/g' nginx.conf && " +
                    f"sed -i 's/green_weight=0/green_weight=10/g' nginx.conf && " +
                    f"nginx -t && nginx -s reload"
                ]
                subprocess.run(initial_split_cmd, check=True)
                logger.info("ì´ˆê¸° íŠ¸ë˜í”½ ë°°ë¶„ ì™„ë£Œ: ë¸”ë£¨ 90% / ê·¸ë¦° 10%")
                
                # 5ë¶„ ëŒ€ê¸°
                logger.info("5ë¶„ ë™ì•ˆ ì´ˆê¸° ë°°í¬ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤...")
                time.sleep(300)
                
                # ëª¨ë‹ˆí„°ë§ ì§€í‘œ í™•ì¸
                # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Prometheus/Grafana APIë¥¼ í†µí•´ ë©”íŠ¸ë¦­ í™•ì¸
                monitoring_ok = True  # ì´ ì˜ˆì œì—ì„œëŠ” í•­ìƒ ì„±ê³µìœ¼ë¡œ ê°€ì •
                
                if monitoring_ok:
                    # íŠ¸ë˜í”½ 50%ë¡œ ì¦ê°€
                    half_split_cmd = [
                        "ssh", 
                        f"{self.config['ssh']['user']}@{load_balancer_host}", 
                        f"cd {load_balancer_config_path} && " +
                        f"sed -i 's/blue_weight=90/blue_weight=50/g' nginx.conf && " +
                        f"sed -i 's/green_weight=10/green_weight=50/g' nginx.conf && " +
                        f"nginx -t && nginx -s reload"
                    ]
                    subprocess.run(half_split_cmd, check=True)
                    logger.info("íŠ¸ë˜í”½ ë°°ë¶„ ì—…ë°ì´íŠ¸: ë¸”ë£¨ 50% / ê·¸ë¦° 50%")
                    
                    # 10ë¶„ ëŒ€ê¸°
                    logger.info("10ë¶„ ë™ì•ˆ ì ˆë°˜ ë°°í¬ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤...")
                    time.sleep(600)
                    
                    # ëª¨ë‹ˆí„°ë§ ì§€í‘œ ì¬í™•ì¸
                    monitoring_ok = True  # ì´ ì˜ˆì œì—ì„œëŠ” í•­ìƒ ì„±ê³µìœ¼ë¡œ ê°€ì •
                    
                    if monitoring_ok:
                        # íŠ¸ë˜í”½ 100% ê·¸ë¦° í™˜ê²½ìœ¼ë¡œ ì „í™˜
                        full_switch_cmd = [
                            "ssh", 
                            f"{self.config['ssh']['user']}@{load_balancer_host}", 
                            f"cd {load_balancer_config_path} && " +
                            f"sed -i 's/blue_weight=50/blue_weight=0/g' nginx.conf && " +
                            f"sed -i 's/green_weight=50/green_weight=100/g' nginx.conf && " +
                            f"nginx -t && nginx -s reload"
                        ]
                        subprocess.run(full_switch_cmd, check=True)
                        logger.info("íŠ¸ë˜í”½ ë°°ë¶„ ì™„ë£Œ: ë¸”ë£¨ 0% / ê·¸ë¦° 100%")
                        
                        # ê·¸ë¦° í™˜ê²½ì„ ë¸”ë£¨ í™˜ê²½ìœ¼ë¡œ ìŠ¹ê²©
                        logger.info("ê·¸ë¦° í™˜ê²½ì„ ë¸”ë£¨ í™˜ê²½ìœ¼ë¡œ ìŠ¹ê²©í•©ë‹ˆë‹¤...")
                        # í™˜ê²½ ë ˆì´ë¸” ìŠ¤ì™‘ (ë‹¤ìŒ ë°°í¬ë¥¼ ìœ„í•´)
                        self.swap_environments()
                        
                        return True
                    else:
                        # ë¬¸ì œ ë°œìƒ ì‹œ ë¡¤ë°±
                        logger.error("ì ˆë°˜ ë°°í¬ ìƒíƒœì—ì„œ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¡¤ë°±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                        self.rollback()
                        return False
                else:
                    # ë¬¸ì œ ë°œìƒ ì‹œ ë¡¤ë°±
                    logger.error("ì´ˆê¸° ë°°í¬ ìƒíƒœì—ì„œ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¡¤ë°±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    self.rollback()
                    return False
            
            # dry run ëª¨ë“œ
            logger.info("(Dry run) íŠ¸ë˜í”½ ì „í™˜ ê³¼ì •ì„ ì‹œë®¬ë ˆì´ì…˜í–ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"íŠ¸ë˜í”½ ì „í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            self.rollback()
            return False
    
    def swap_environments(self):
        """ë¸”ë£¨/ê·¸ë¦° í™˜ê²½ ìŠ¤ì™‘"""
        if not self.dry_run:
            # í™˜ê²½ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
            env_config_path = os.path.join(os.path.dirname(self.config_path), "environments.json")
            
            try:
                with open(env_config_path, 'r') as f:
                    env_config = json.load(f)
                
                # ë¸”ë£¨/ê·¸ë¦° í™˜ê²½ ìŠ¤ì™‘
                blue_env = env_config['environments']['blue']
                green_env = env_config['environments']['green']
                
                env_config['environments']['blue'] = green_env
                env_config['environments']['green'] = blue_env
                
                with open(env_config_path, 'w') as f:
                    json.dump(env_config, f, indent=2)
                
                logger.info("ë¸”ë£¨/ê·¸ë¦° í™˜ê²½ ì„¤ì •ì„ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"í™˜ê²½ ìŠ¤ì™‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def rollback(self):
        """ë°°í¬ ë¡¤ë°±"""
        logger.info("ë°°í¬ ë¡¤ë°±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        if not self.dry_run:
            try:
                # ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • ë³µì› (100% ë¸”ë£¨ í™˜ê²½ìœ¼ë¡œ ì „í™˜)
                load_balancer_host = self.config['load_balancer']['host']
                load_balancer_config_path = self.config['load_balancer']['config_path']
                
                rollback_cmd = [
                    "ssh", 
                    f"{self.config['ssh']['user']}@{load_balancer_host}", 
                    f"cd {load_balancer_config_path} && " +
                    f"sed -i 's/blue_weight=[0-9]*/blue_weight=100/g' nginx.conf && " +
                    f"sed -i 's/green_weight=[0-9]*/green_weight=0/g' nginx.conf && " +
                    f"nginx -t && nginx -s reload"
                ]
                subprocess.run(rollback_cmd, check=True)
                logger.info("íŠ¸ë˜í”½ì„ ë¸”ë£¨ í™˜ê²½ìœ¼ë¡œ 100% ë³µì›í–ˆìŠµë‹ˆë‹¤.")
                
                # ë²„ì „ íƒœê·¸ ì‚­ì œ
                tag_name = f"v{self.version}"
                delete_tag_cmd = ["git", "push", "--delete", "origin", tag_name]
                delete_local_tag_cmd = ["git", "tag", "-d", tag_name]
                
                try:
                    subprocess.run(delete_tag_cmd, check=False)
                    subprocess.run(delete_local_tag_cmd, check=False)
                    logger.info(f"ë°°í¬ íƒœê·¸ {tag_name}ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
                except:
                    logger.warning(f"ë°°í¬ íƒœê·¸ {tag_name} ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                logger.info("ë¡¤ë°±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"ë¡¤ë°± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        else:
            logger.info("(Dry run) ë¡¤ë°± ê³¼ì •ì„ ì‹œë®¬ë ˆì´ì…˜í–ˆìŠµë‹ˆë‹¤.")
    
    def perform_post_deployment_tasks(self):
        """ë°°í¬ í›„ ì‘ì—…"""
        logger.info("ë°°í¬ í›„ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            if not self.dry_run:
                # ë°°í¬ ì•Œë¦¼ ë°œì†¡
                self.send_deployment_notification()
                
                # ì´ë²¤íŠ¸ ë¡œê¹…
                self.log_deployment_event()
                
                # í™˜ê²½ ìƒíƒœ í™•ì¸
                self.verify_environment_health()
            
            logger.info("ë°°í¬ í›„ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"ë°°í¬ í›„ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def send_deployment_notification(self):
        """ë°°í¬ ì•Œë¦¼ ë°œì†¡"""
        try:
            webhook_url = self.config['notifications']['slack_webhook']
            
            message = {
                "text": f"ğŸš€ ì •ì‹ ë²„ì „ v{self.version} ë°°í¬ ì™„ë£Œ!",
                "blocks": [
                    {
                        "type": "header",
                        "text": {
                            "type": "plain_text",
                            "text": f"ğŸš€ ì •ì‹ ë²„ì „ v{self.version} ë°°í¬ ì™„ë£Œ!"
                        }
                    },
                    {
                        "type": "section",
                        "fields": [
                            {
                                "type": "mrkdwn",
                                "text": f"*ë°°í¬ ID:*\n{self.deployment_id}"
                            },
                            {
                                "type": "mrkdwn",
                                "text": f"*ë°°í¬ ì‹œê°„:*\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                            }
                        ]
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "ëª¨ë“  ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ <https://monitoring.christmas-trading.com|ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ>ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                        }
                    }
                ]
            }
            
            requests.post(webhook_url, json=message)
            logger.info("ë°°í¬ ì•Œë¦¼ì„ ë°œì†¡í–ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"ë°°í¬ ì•Œë¦¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def log_deployment_event(self):
        """ë°°í¬ ì´ë²¤íŠ¸ ë¡œê¹…"""
        try:
            event_log = {
                "deployment_id": self.deployment_id,
                "version": self.version,
                "timestamp": datetime.now().isoformat(),
                "status": "success",
                "environment": "production"
            }
            
            log_dir = os.path.join(os.path.dirname(self.config_path), "logs")
            os.makedirs(log_dir, exist_ok=True)
            
            log_file = os.path.join(log_dir, f"deployment_log_{datetime.now().strftime('%Y%m%d')}.json")
            
            if os.path.exists(log_file):
                with open(log_file, 'r') as f:
                    logs = json.load(f)
            else:
                logs = []
            
            logs.append(event_log)
            
            with open(log_file, 'w') as f:
                json.dump(logs, f, indent=2)
            
            logger.info("ë°°í¬ ì´ë²¤íŠ¸ë¥¼ ë¡œê¹…í–ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"ë°°í¬ ì´ë²¤íŠ¸ ë¡œê¹… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def verify_environment_health(self):
        """í™˜ê²½ ìƒíƒœ í™•ì¸"""
        try:
            # ë¸”ë£¨ í™˜ê²½(ì´ì „ ê·¸ë¦° í™˜ê²½)ì˜ ìƒíƒœ í™•ì¸
            blue_env = self.config['environments']['blue']
            health_check_url = f"https://{blue_env['domain']}/health"
            
            response = requests.get(health_check_url, timeout=10)
            if response.status_code == 200 and response.json().get("status") == "ok":
                logger.info("í”„ë¡œë•ì…˜ í™˜ê²½ì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.")
                
                # ì¶”ê°€ ì§€í‘œ í™•ì¸
                metrics_url = f"https://{blue_env['domain']}/metrics"
                metrics_response = requests.get(metrics_url, timeout=10)
                
                if metrics_response.status_code == 200:
                    metrics = metrics_response.json()
                    logger.info(f"API ì‘ë‹µ ì‹œê°„: {metrics.get('api_response_time_ms', 'N/A')}ms")
                    logger.info(f"ì˜¤ë¥˜ìœ¨: {metrics.get('error_rate_percentage', 'N/A')}%")
                    logger.info(f"CPU ì‚¬ìš©ë¥ : {metrics.get('cpu_usage_percentage', 'N/A')}%")
                    logger.info(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics.get('memory_usage_percentage', 'N/A')}%")
            else:
                logger.warning(f"í”„ë¡œë•ì…˜ í™˜ê²½ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.error(f"í™˜ê²½ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def run(self):
        """ì „ì²´ ë°°í¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info(f"ì •ì‹ ë²„ì „ v{self.version} ë°°í¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ë°°í¬ ë‹¨ê³„ ì‹¤í–‰
        if not self.prepare_deployment():
            logger.error("ë°°í¬ ì¤€ë¹„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        if not self.execute_deployment():
            logger.error("ë°°í¬ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        if not self.migrate_database():
            logger.error("ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            self.rollback()
            return False
        
        if not self.switch_traffic():
            logger.error("íŠ¸ë˜í”½ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            # ë¡¤ë°±ì€ switch_traffic ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨
            return False
        
        if not self.perform_post_deployment_tasks():
            logger.warning("ë°°í¬ í›„ ì‘ì—… ì¤‘ ì¼ë¶€ ì‹¤íŒ¨ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë°°í¬ëŠ” ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤.")
        
        logger.info(f"ì •ì‹ ë²„ì „ v{self.version} ë°°í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        self.deployment_success = True
        return True

def main():
    parser = argparse.ArgumentParser(description="ì •ì‹ ë²„ì „ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--config", "-c", default="environments/production/config/deployment_config.json", 
                        help="ë°°í¬ ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--dry-run", "-d", action="store_true", 
                        help="ì‹¤ì œ ë³€ê²½ ì—†ì´ ë°°í¬ ê³¼ì •ë§Œ ì‹œë®¬ë ˆì´ì…˜")
    parser.add_argument("--version", "-v", default="1.0.0",
                        help="ë°°í¬í•  ë²„ì „ (ê¸°ë³¸ê°’: 1.0.0)")
    
    args = parser.parse_args()
    
    deployer = ProductionDeployer(args.config, args.dry_run)
    deployer.version = args.version
    success = deployer.run()
    
    if not success:
        sys.exit(1)

if __name__ == "__main__":
    main() 