# Christmas 프로젝트 RAG 시스템 설계 문서

## 1. 개요

RAG(Retrieval-Augmented Generation) 시스템은 Christmas 프로젝트 문서를 효율적으로 검색하고 질의에 대한 응답을 생성하는 시스템입니다. 이 문서는 RAG 시스템의 설계, 아키텍처, 컴포넌트 및 데이터 흐름을 상세히 설명합니다.

## 2. 시스템 아키텍처

RAG 시스템은 아래와 같은 주요 컴포넌트로 구성됩니다:

```
[사용자] <-> [RAG 웹 인터페이스] <-> [RAG API] <-> [벡터 데이터베이스]
                                     |
                              [LLM 서비스(OpenAI)]
```

### 2.1 컴포넌트 설명

#### 2.1.1 벡터 데이터베이스 (Weaviate)
- 문서 청크를 벡터 형태로 저장하고 검색하는 역할
- 의미 기반 유사도 검색 지원
- 스키마 기반 데이터 모델링

#### 2.1.2 RAG API 서버
- FastAPI 기반 RESTful API
- 문서 검색, 색인, 질의 응답 엔드포인트 제공
- 비동기 처리 지원

#### 2.1.3 RAG 웹 인터페이스
- Express.js 기반 웹 서버
- 사용자 친화적 인터페이스
- API 서버와 통신

#### 2.1.4 LLM 서비스 (OpenAI)
- 검색된 문서 기반 응답 생성
- 문서 벡터화를 위한 임베딩 제공

## 3. 모듈 구조

### 3.1 파일 구조
```
app/
├── rag/
│   ├── __init__.py
│   ├── api.py            # FastAPI 애플리케이션 및 라우트
│   ├── retriever.py      # 문서 검색 모듈
│   ├── indexer.py        # 문서 색인 모듈
│   └── generator.py      # 응답 생성 모듈
├── web/
│   ├── rag_interface.js  # Express.js 웹 서버
│   └── rag/
│       └── index.html    # 웹 인터페이스
scripts/
└── rag_indexer.py        # 색인 생성 도구
```

### 3.2 모듈별 설계

#### 3.2.1 RAG Retriever 모듈 (retriever.py)
- **목적**: 벡터 데이터베이스에서 사용자 질의와 관련된 문서 검색
- **주요 기능**:
  - Weaviate 클라이언트 관리
  - 의미 기반 유사도 검색
  - 검색 결과 필터링 및 정제
  - 모의 검색 모드 지원 (API 키 없는 환경용)
- **클래스 구조**:
  - `DocumentRetriever`: 문서 검색 클래스
  - `MockRetriever`: 모의 검색 클래스

#### 3.2.2 RAG Indexer 모듈 (indexer.py)
- **목적**: 마크다운 문서를 처리하여 벡터 데이터베이스에 색인화
- **주요 기능**:
  - 마크다운 파싱 및 섹션 추출
  - 청크 분할 및 토큰 관리
  - 색인 상태 관리
  - 배치 색인 처리
- **핵심 기능**:
  - `extract_sections()`: 마크다운에서 섹션 추출
  - `chunk_text()`: 텍스트를 최적 크기로 분할
  - `index_markdown_file()`: 개별 파일 색인화
  - `index_directory()`: 디렉토리 색인화

#### 3.2.3 RAG Generator 모듈 (generator.py)
- **목적**: 검색된 문서를 기반으로 질의에 대한 응답 생성
- **주요 기능**:
  - OpenAI API 통합
  - 컨텍스트 구성 및 프롬프트 설계
  - 응답 생성 및 소스 추적
  - 모의 응답 생성 지원
- **핵심 기능**:
  - `generate_response()`: 응답 생성 함수
  - `extract_sources()`: 응답에서 참조 소스 추출

#### 3.2.4 RAG API 모듈 (api.py)
- **목적**: RESTful API 엔드포인트 제공
- **주요 기능**:
  - 질의 처리 엔드포인트
  - 색인 관리 엔드포인트
  - 상태 확인 엔드포인트
  - 비동기 작업 지원
- **엔드포인트**:
  - `POST /query`: 문서 기반 질의 처리
  - `POST /index`: 문서 색인화 작업 시작
  - `GET /status`: 색인 상태 확인

#### 3.2.5 RAG Web Interface (rag_interface.js)
- **목적**: 사용자 인터페이스 제공
- **주요 기능**:
  - Express.js 웹 서버
  - API 프록시 라우팅
  - 정적 파일 제공
- **라우트**:
  - `GET /`: 메인 페이지
  - `GET /api/status`: 상태 확인
  - `POST /api/index`: 색인화 요청
  - `POST /api/query`: 질의 처리

## 4. 데이터 흐름

### 4.1 색인 프로세스
1. 사용자가 색인 명령 실행 (웹 인터페이스 또는 CLI)
2. 지정된 디렉토리의 마크다운 파일 스캔
3. 각 파일을 섹션별로 분리
4. 섹션을 적절한 크기의 청크로 분할
5. 각 청크를 OpenAI API를 통해 벡터로 변환
6. 벡터와, 원본 텍스트, 메타데이터를 Weaviate에 저장
7. 색인 상태 업데이트

### 4.2 검색 및 응답 생성 프로세스
1. 사용자가 질의 입력
2. 질의를 OpenAI API를 통해 벡터로 변환
3. 벡터 데이터베이스에서 유사도 검색 수행
4. 최상위 유사 문서 청크 검색
5. 검색된 청크를 기반으로 LLM 프롬프트 구성
6. OpenAI API를 통해 응답 생성
7. 응답과 참조 소스 정보 반환

## 5. 구현 세부사항

### 5.1 벡터 데이터베이스 스키마
```json
{
  "classes": [
    {
      "class": "ChristmasDocument",
      "description": "Christmas 프로젝트 문서 청크",
      "vectorizer": "text2vec-openai",
      "properties": [
        {
          "name": "content",
          "dataType": ["text"],
          "description": "문서 청크 내용"
        },
        {
          "name": "file_path",
          "dataType": ["string"],
          "description": "원본 파일 경로"
        },
        {
          "name": "section",
          "dataType": ["string"],
          "description": "문서 섹션"
        },
        {
          "name": "chunk_id",
          "dataType": ["int"],
          "description": "청크 ID"
        },
        {
          "name": "metadata",
          "dataType": ["text"],
          "description": "추가 메타데이터"
        }
      ]
    }
  ]
}
```

### 5.2 LLM 프롬프트 설계
시스템 프롬프트:
```
당신은 Christmas 프로젝트에 대한 전문가입니다. 
다음 문서에 포함된 정보를 바탕으로 질문에 정확하게 답변하세요.
각 참조 문서는 Document X: {...} 형식으로 제공됩니다.
참조 문서에 없는 내용은 답변하지 마세요.
답변에 참조한 문서를 (Document X:섹션) 형식의 인용으로 표시하세요.
```

### 5.3 모의 모드
- API 키가 없을 때 자동으로 모의 모드로 전환
- 가상 문서 데이터 생성 및 검색
- 테스트 및 개발 환경에서 유용

## 6. 배포 구성

### 6.1 Docker 구성
- `docker-compose.rag.yml`: RAG 시스템 Docker Compose 설정
- 컨테이너:
  - weaviate: 벡터 데이터베이스
  - rag-api: FastAPI 서버
  - rag-web: Express.js 웹 서버
- 볼륨:
  - weaviate-data: 벡터 데이터베이스 영속성

### 6.2 환경 변수
- `OPENAI_API_KEY`: OpenAI API 키
- `WEAVIATE_URL`: Weaviate 서버 URL
- `RAG_API_URL`: RAG API 서버 URL

## 7. 확장성 및 성능

### 7.1 성능 최적화
- 청크 크기 최적화: 500토큰 기준
- 벡터 차원 최적화: OpenAI 임베딩 모델 사용
- 캐싱: 자주 사용되는 쿼리 결과 캐싱 가능

### 7.2 확장 방향
- 추가 문서 형식 지원 (PDF, HTML 등)
- 다국어 지원 확장
- 실시간 문서 업데이트 지원
- 커스텀 임베딩 모델 지원

## 8. 모니터링 및 평가

### 8.1 모니터링 지표
- 색인 속도 및 크기
- 검색 지연 시간
- 응답 생성 시간
- 검색 정확도

### 8.2 품질 평가
- 응답 정확성
- 소스 인용 정확성
- 사용자 피드백 분석

## 9. 사용 예제

### 9.1 색인 생성
```bash
python scripts/rag_indexer.py --directory docs --extensions md
```

### 9.2 API를 통한 질의
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Christmas 프로젝트란 무엇인가요?", "max_chunks": 5, "min_score": 0.7}'
```

## 10. 참고 자료

- [Weaviate 문서](https://weaviate.io/developers/weaviate)
- [OpenAI API 문서](https://platform.openai.com/docs/api-reference)
- [FastAPI 문서](https://fastapi.tiangolo.com/)
- [LangChain RAG 가이드](https://js.langchain.com/docs/modules/data_connection/retrievers/)